"""Template processor for handling copy instructions and file templates."""

from pathlib import Path
from typing import Dict, Any
import logging

logger = logging.getLogger(__name__)


class TemplateProcessor:
    """Handles template processing and copy instructions for different LLMs."""
    
    def __init__(self):
        """Initialize the template processor."""
        self.templates_path = Path(__file__).parent.parent / "templates"
    
    def get_copy_instructions(self) -> str:
        """Get detailed copy instructions for different LLMs."""
        return """# How to Use Your Generated LLM Context

## Overview
Your generated `LLM_CONTEXT.md` file contains universal coding standards and project context optimized for any LLM. Here's how to use it with different LLM platforms:

---

## ðŸ¤– Claude (Anthropic)

### Method 1: CLAUDE.md File (Recommended)
1. **Rename** `LLM_CONTEXT.md` to `CLAUDE.md`
2. **Place** in your project root directory
3. **That's it!** Claude automatically reads CLAUDE.md files

### Method 2: Direct Copy-Paste
1. Copy the entire content of `LLM_CONTEXT.md`
2. Paste at the beginning of your conversation
3. Add: "Please follow these guidelines throughout our conversation"

---

## ðŸ’¬ ChatGPT (OpenAI)

### Method 1: Project Custom Instructions (Recommended)
1. Create a **new Project** in ChatGPT
2. Click **"Customize ChatGPT"** â†’ **"Custom Instructions"**
3. Copy the content from `LLM_CONTEXT.md`
4. Paste into the **"How would you like ChatGPT to respond?"** section

### Method 2: Knowledge Base Upload
1. In your ChatGPT Project, click **"Create"** â†’ **"Upload files"**
2. Upload your `LLM_CONTEXT.md` file
3. ChatGPT will reference it automatically

### Method 3: Direct Context
1. Start conversation with: "Please follow these coding standards:"
2. Copy and paste the content from `LLM_CONTEXT.md`

---

## ðŸ” Gemini (Google)

### Method 1: Firebase Studio (.idx/airules.md)
1. **Copy** `LLM_CONTEXT.md` to `.idx/airules.md`
2. Place in your project's `.idx/` directory
3. Gemini will automatically apply these rules

### Method 2: GitHub Code Assist (.gemini/styleguide.md)
1. Create a `.gemini/` folder in your repository root
2. **Copy** `LLM_CONTEXT.md` to `.gemini/styleguide.md`
3. GitHub Code Assist will use this as context

### Method 3: Direct Reference
1. Copy the content and reference it as needed
2. Use as system prompt for Gemini API calls

---

## ðŸ”„ Other LLMs

### General Approach
1. **System Prompt:** Use the content as a system prompt
2. **Context Document:** Reference key sections as needed
3. **File Naming:** Adapt to your LLM's conventions

### Popular LLMs:
- **Cursor:** Copy to `.cursorrules` file
- **GitHub Copilot:** Reference in code comments
- **CodeWhisperer:** Use as inline documentation
- **Local LLMs:** Include in system prompt

---

## ðŸ’¡ Pro Tips

### Token Optimization
- The context is already optimized for token efficiency
- Focus on the most relevant sections for your current task
- Use the project detection results to prioritize content

### Multi-LLM Workflow
- Keep the original `LLM_CONTEXT.md` as your master copy
- Create specific copies for each LLM you use
- Update all copies when standards change

### Maintenance
- Re-generate context when project structure changes significantly
- Update when adding new languages or frameworks
- Keep standards current with your team's practices

---

## ðŸ“Š Effectiveness Metrics

This universal context approach provides:
- **~40% token reduction** vs. verbose explanations
- **Consistent standards** across different LLMs
- **Faster setup** than manual configuration
- **Better context retention** in longer conversations

---

*Generated by llm-programming-setup-mcp â€¢ Optimized for all LLM platforms*"""
    
    def get_llm_specific_instructions(self, llm_type: str) -> str:
        """Get instructions specific to one LLM type."""
        instructions = {
            "claude": """## Claude Setup Instructions

1. **Rename** your `LLM_CONTEXT.md` to `CLAUDE.md`
2. **Place** in your project root directory
3. **Verify** Claude can read it by asking: "What coding standards should I follow?"

**Why this works:** Claude automatically reads CLAUDE.md files in your project directory.""",
            
            "chatgpt": """## ChatGPT Setup Instructions

1. **Create** a new Project in ChatGPT
2. **Go to** Project Settings â†’ Custom Instructions
3. **Copy** your `LLM_CONTEXT.md` content
4. **Paste** into "How would you like ChatGPT to respond?"

**Alternative:** Upload LLM_CONTEXT.md as a knowledge base file.""",
            
            "gemini": """## Gemini Setup Instructions

**For Firebase Studio:**
1. **Copy** `LLM_CONTEXT.md` to `.idx/airules.md`
2. **Place** in your project's `.idx/` directory

**For GitHub Code Assist:**
1. **Create** `.gemini/` folder in repository root
2. **Copy** `LLM_CONTEXT.md` to `.gemini/styleguide.md`""",
            
            "universal": self.get_copy_instructions()
        }
        
        return instructions.get(llm_type, instructions["universal"])
    
    def generate_file_template(self, llm_type: str, content: str) -> Dict[str, str]:
        """Generate file template for specific LLM type."""
        templates = {
            "claude": {
                "filename": "CLAUDE.md",
                "content": content
            },
            "chatgpt": {
                "filename": "CHATGPT_CONTEXT.md",  
                "content": f"# ChatGPT Project Context\n\n*Copy this content to your ChatGPT Project's Custom Instructions*\n\n---\n\n{content}"
            },
            "gemini": {
                "filename": ".idx/airules.md",
                "content": f"# Gemini AI Rules\n\n{content}"
            },
            "cursor": {
                "filename": ".cursorrules",
                "content": content
            },
            "universal": {
                "filename": "LLM_CONTEXT.md",
                "content": content
            }
        }
        
        return templates.get(llm_type, templates["universal"])
    
    def get_supported_llms(self) -> Dict[str, str]:
        """Get list of supported LLM types and their descriptions."""
        return {
            "claude": "Anthropic Claude (CLAUDE.md)",
            "chatgpt": "OpenAI ChatGPT (Project Custom Instructions)",
            "gemini": "Google Gemini (.idx/airules.md or .gemini/styleguide.md)",
            "cursor": "Cursor AI (.cursorrules)",
            "universal": "Universal format (LLM_CONTEXT.md)"
        }